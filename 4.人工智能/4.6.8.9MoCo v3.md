# MoCo v3

# 前言

在 VIT 出来之后，大家也都想着把对比学习的 backbone 换成 VIT。于是新的缝合怪自然而然地诞生了

MoCo v3，它缝合了 MoCo 和 SimSiam，以及新的骨干网络 VIT。

# 模型架构

可能因为和前面的工作太像了，作者就没有给模型总览图，我们借 MoCo 的总览图来讲

![](https://cdn.xyxsw.site/boxcnhxg4HZw2NExIbYZxQGISze.png)

总体架构其实没有太多变化，还是 memory bank 的结构，右边也还是动量编码器，不过加入了 SimCLR 提出的 projection head（就是额外的那层 mlp），并且在对比上用了 SimSiam 的预测头对称学习方式。具体也不展开了，都是老东西缝合在一起。

# 讲这篇文章主要是冲着 VIT 来的

作者在用 VIT 做骨干网络训练的时候，发现如下问题：

![](https://cdn.xyxsw.site/boxcnMMhbVk6wc81H8BSoack7Mg.png)

在使用 VIT 训练的时候，batchsize 不算太大时训练很平滑，但是一旦 batchsize 变大，训练的图像就会出现如上图这样的**波动**。于是作者去查看了每一层的梯度，发现问题出在**VIT 的第一层线性变换**上。也就是下图中的粉色那个层，**把图片打成 patch 后展平做的线性变换**。

![](https://cdn.xyxsw.site/boxcniBkiypcv6IQbxr9D6JukOb.png)

在这一层中，梯度会出现波峰，而正确率则会突然下跌。

作者就想，既然你训练不好，我就把你冻住，不让它训练，然后就能成功运用了。而且这个 trick 对几乎所有的对比学习模型都有效果。
