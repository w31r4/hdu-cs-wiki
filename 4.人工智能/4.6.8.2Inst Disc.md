# Inst Disc

这篇论文是对比学习的一篇开山之作，后续很多论文都参考了它的方法，这里不止讲了论文本身，还有一些扩展补充

## 提出的背景

作者团队发现，当把一张豹子的图片喂给以前的有监督训练的模型。得分最高的都是跟豹子很像的动物，比如雪豹，猎豹，而分数最低的几个都是跟豹子一点都不像的东西比如救生艇，书架。

作者团队认为，让这些猎豹，雪豹的标签相互接近（指互相在判别时都排名靠前）的原因并不是它们有相似的标签，而是它们有相似的图像特征。

![](https://cdn.xyxsw.site/boxcnrR3eFvOSKYRH8Ni0dvHYkc.png)

## 个体判别任务

既然有了上面这个发现，那么作者想我能不能把分类任务推到极致呢？

于是他们**把每一个图片当作一个类别**，去跟其他的图片做对比，具体模型如下

![](https://cdn.xyxsw.site/boxcnPNukes2FlNwUFSKiqIJEbd.png)

先介绍一下模型结构：

1.CNN 用的是经典的 RES50，没什么特殊。

2.后面接了一个 Non-param Softmax（非参数 softmax），其实就是一个不被训练的，把所有特征投射到超球面上的一个分类头（把所有特征模长变为 1）。

3.后面的**Memory Bank**是这篇文章的**重点**，它是一个**动态字典**。我们把每一个图片抽取出来的特征存入 memory bank，每次计算时抽取其中部分作为一个 batch 进行对比学习，把更新后的模型得到的特征替换 memory bank 里原先的特征。

4.具体损失函数用的是一个叫 NCEloss 的损失，它把多分类问题分为**若干个二分类问题**，**是**与**不是**，每个 batch 中只有一个的 ground truth 是’yes‘，其余都是’no‘

在训练的时候，相当于是有一组以前的编码器抽取的特征 A,B,C,D...，一组当前编码器抽取的特征 a,b,c,d...，对它们进行对比学习。对 a 来说，A 是正样本，其他都是负样本，同理类推。

## 一些小 trick 和小细节

上面这些就是这篇文章的主体，后面是一些对后续工作有贡献的小 trick 和细节：

### 动量更新

用动量更新的方法去更新 memory bank 中的特征

也就是让特征的变化**不那么剧烈**

原因：如果一直保持更新，**特征总体的变化就会比较大**，而我们在大数据集上训练的时候，等第二次调用一个特征时，它跟现在的特征分布已经大相径庭，那就不好训练了，也就是**特征缺乏一致性**。因此我们引入动量更新来确保特征进行平稳的改变，而非突变。

#### 关于动量的小拓展

大家在使用诸如 SGD，Adam 等优化器的时候一定见过动量这个概念了，这里给不了解这个概念的读者简单讲解一下动量这个概念：

A 是起始点，B 是第一次更新后的点，C 是第二次更新后的点

![](https://cdn.xyxsw.site/boxcn5zfD155Joy1eD5CvbZXZnc.png)

而在我们刚刚提到的动量更新里，它的公式可以概括为：

![](https://cdn.xyxsw.site/boxcnTLEK31rFmuRo2MOWGRBoYe.png)

m 表示动量，k 是新的特征，q 是上一个特征，只要设置小的动量就可以使改变放缓。

# 总结

总体来说，Inst Disc 把对比学习成功引入了 CV 领域，核心思想是构建动态字典进行对比学习

**PS：若无特殊说明，最后保留下来去做下游任务的模型只有编码器，其他都删除了。**
