# SimCLR

顾名思义，以‘SIMPLE’为主，这个模型主打的就是简单。

# 模型结构

x 是输入的图片，它经过两种不同的数据增强得到 xi 和 xj 两个正样本，而同一个 mini-batch 里的所有其他样本都作为负样本。<del>说白了还是个体判别任务</del>

![](https://cdn.xyxsw.site/boxcnq5TYzSltn6CsPM3Bn3xxAb.png)

左右的**f 都是编码器**，并且是**完全一致共享权重**的，可以说是同一个。

而 g 是一层 mlp 结构，只在训练中使用，**应用到下游任务时用的仅仅是 f**（与前面几篇一样都是 RES50），很神奇的是，就仅仅多了这么一层 mlp，它在 imagenet 上的正确率直接加了十个点。

关于这点也很奇怪，作者做了很多实验但是也没有很合理的解释。

最后的对比学习是对 zi 和 zj 做的。

下面这个是更加具体的流程图

![](https://cdn.xyxsw.site/boxcnj3FZsRiJbWsKW07b9B8Fkb.png)

# 总结

因为这个真的很简单，没有太多可讲的，它就是单纯的简单且效果拔群，想具体了解数据增强相关或者具体效果对比的可以去看一下[原论文](https://arxiv.org/pdf/2002.05709v3)。

# 另外

SimCLR 也有 v2，缝合了 MoCo 的方法，同样不展开了。
