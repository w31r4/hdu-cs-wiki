# 工欲善其事，必先利其器

> 有一个英语词汇叫做 Handy，讲的是便利的，易使用的，当你有一个良好的环境配置时候，编程将变得 handy，随手打开即可编程，一点都不复杂，所以配置好的环境，是未来学习快速进步的必要保障。

首先来了解一下深度学习框架

## 深度学习框架

![](https://cdn.xyxsw.site/boxcnWLzi1LIWLCncrXcTcjAKne.png)

### 1、深度学习框架是什么

在深度学习初始阶段，每个深度学习研究者都需要写大量的重复代码。

为了提高工作效率，他们就将这些代码写成了框架放到网上让所有研究者一起使用。

作一个简单的比喻，一套深度学习框架就是一套积木，各个组件就是某个模型或算法的一部分，你可

以自己设计如何使用积木去堆砌符合你数据集的积木。

#### 思考题

自行了解张量和基于张量的各种操作。

### 2、为什么需要深度学习框架

显然是为了降低使用门槛。 深度学习对硬件环境的依赖很高，对于开发者有较高的门槛，深度学习计

算框架的出现，屏蔽了大量硬件环境层面的开发代价，使研究者和开发人员可以专注于算法的实现，

快速迭代。

## TensorFlow 和 pytorch

这么多的框架，我们应该如何选择呢（好吧直接就 TensorFlow 和 pytorch 了）

### 1. TensorFlow

#### 开发语言

基于 python 编写，通过 C/C++ 引擎加速，是 Google 开源的第二代深度学习框架。

#### 编程语言

Python 是处理 TensorFlow 的最方便的客户端语言。不过，JavaScript、C++、Java、Go、C#和 Julia 也提供了实验性的交互界面。

#### 优点

（不讲人话的版本）

处理循环神经网 RNN 非常友好。其用途不止于深度学习，还可以支持增强学习和其他算法。

内部实现使用了向量运算的符号图方法，使用图 graph 来表示计算任务，使新网络的指定变得相当容易，支持快速开发。TF 使用静态计算图进行操作。也就是说，我们首先定义图，然后运行计算，如果需要对架构进行更改，我们将重新训练模型。TF 选择这种方法是为了提高效率，但是许多现代神经网络工具能够在不显著降低学习速度的情况下，同时兼顾到在学习过程中进行改进。在这方面，TensorFlow 的主要竞争对手是 Pythorch。

（讲人话啊喂！！）

- 谷歌爸爸一撑腰，研究代码两丰收
- 新版 TensorFlow API（STFW) 较简洁
- 天生和谷歌云兼容
- 有良好的推断支持
- 功能十分强大！

#### 缺点

（不讲人话的版本）

目前 TensorFlow 还不支持“内联（inline）”矩阵运算，必须要复制矩阵才能对其进行运算，复制庞大的矩阵会导致系统运行效率降低，并占用部分内存。

TensorFlow 不提供商业支持，仅为研究者提供的一种新工具，因此公司如果要商业化需要考虑开源协议问题。

（讲人话！！）

- API 不稳定
- 学习成本高
- 开发成本高
- 会出现前面版本存在的功能后面版本直接没了

### 2.pytorch

#### 开发语言

Facebook 用 Lua 编写的开源计算框架，支持机器学习算法。Tensorflow 之后深入学习的主要软件工具是 PyTorch。

Facebook 于 2017 年 1 月开放了 Torch 的 Python API ― PyTorch 源代码。

#### 编程语言

PyTorch 完全基于 Python。

（直接说人话吧）

#### 优点

- 上手容易
- 代码简洁
- 有较好的灵活性和速度
- 发展快速，现在已经支持 TPU
- API 相对稳定
- 里面附带许多开源模型代码可以直接调用
- 非常建议使用 pytorch，tensorflow 版本更迭会导致很多代码失效，前期不建议使用。

#### 缺点

-

没有 Keras API 那么简洁

- 一些功能难以实现

## 安装

### Pytorch

官网如下

![](https://cdn.xyxsw.site/boxcnaF9UWNcr5pt99Zu5Wr0PTg.png)

![](https://cdn.xyxsw.site/boxcnqHCP5KiSF4Vmc6M1cjEXKg.png)

选择 Conda 或者 Pip 安装皆可

有独立显卡请下载 CUDA，没有的话请下载 CPU

最后选择 CUDA 版本或者 CPU 版本运行指令就好了

### Tip：conda 换源

如果你使用 conda 安装 pytorch 太慢或者失败，不妨换个下载源试试

在 cmd 命令行中，输入添加以下命令：

```bash
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --set show_channel_urls yes
```

### TensorFlow

![](https://cdn.xyxsw.site/boxcn5u9u9M6DPRh83ufoSwfuof.png)

#### 教程

[在 Windows 上配置 pytorch！（CPU 和 GPU 版）](https://www.bilibili.com/video/BV1YY4y1B7cA)

<Bilibili bvid='BV1YY4y1B7cA'/>

[Windows 下 PyTorch 入门深度学习环境安装与配置 CPU GPU 版](https://www.bilibili.com/video/BV1S5411X7FY)

<Bilibili bvid='BV1S5411X7FY'/>

[最新 TensorFlow 2.8 极简安装教程](https://www.bilibili.com/video/BV1i34y1r7dv)

<Bilibili bvid='BV1i34y1r7dv'/>

#### 思考题：为什么需要 CUDA 版本？？？

cuda 版本需要额外配置，我们将这个任务留给聪明的你！！！

### Tips：Windows 和 Linux 如何查看显卡信息

#### windows

同时按下键盘的 win+r 键，打开 cmd，键入 `dxdiag` 然后回车
系统、显卡、声卡以及其他输入设备的信息都在这里了。（给出我的界面）

![](https://cdn.xyxsw.site/boxcnXHceTuUl0XzCNJv9RqHN9c.png)

cuda 版本查看

桌面空白位置摁下右键

![](https://cdn.xyxsw.site/boxcnbxhAei6H4OWjaN0Hp0YICg.png)

![](https://cdn.xyxsw.site/boxcnp9i1SagOxXd17W9BiP3RNe.png)

![](https://cdn.xyxsw.site/boxcngaZNZB3XLSJia0rk0DgGbe.png)

#### linux

打开 bash 键入

```bash
nvidia-smi
```

## 很多人会混淆的东西（非常重要）

### cuda driver version / cuda runtime version

通常大家所指的 cuda 是位于/usr/local 下的 cuda

![](https://cdn.xyxsw.site/boxcntFGELTpdcVoigy5ldCorAb.png)

当然可以看到 cuda 是 cuda-11.6 所指向的软链接（类似 windows 的快捷方式），所以我们如果要切换 cuda 版本只需要改变软链接的指向即可。

![](https://cdn.xyxsw.site/boxcnTB39MtPKBr9CgufCpSIYuf.png)

cuda driver version 是 cuda 的驱动版本。

cuda runtimer version 是我们实际很多时候我们实际调用的版本。

二者的版本是可以不一致的。如下图所示：

![](https://cdn.xyxsw.site/boxcnATNfI2spkNsXbqtIuwwY6c.png)

![](https://cdn.xyxsw.site/boxcnz03UebyZ42JNOXpdUfjMBg.png)

一般来讲 cuda driver 是向下兼容的。所以 cuda driver version >= cuda runtime version 就不会太大问题。

如果我们用 C++ 写 CUDA，具体的说就是编写以.cu 为后缀的文件。就是用 nvcc（cuda 编译器）去编译的，nvcc 是 cuda runtime api 的一部分。cuda runtime 只知道自身构建时的版本，并不知道是否 GPU driver 的版本，甚至不知道是否安装了 GPU driver。

### Pytorch/tensorflow 使用的 cuda 版本

以 pytorch 为例，可以看到在安装过程中我们选择的 cuda 版本是 10.2

![](https://cdn.xyxsw.site/boxcns8yMCuacj0A2BbMU6ZB08b.png)

那么这个 cudatookit10.2 和 nvidia-smi 的 11.7 以及 nvcc -V 的 11.4 三者有什么区别呢？

pytorch 实际只需要 cuda 的链接文件，即.so 文件，这些链接文件就都包含的 cudatookkit 里面。并不需要 cuda 的头文件等其他东西，如下所示

![](https://cdn.xyxsw.site/boxcnXWjMnlXjMg2lA1ApjoUhnh.png)

所以我们如果想让使用 pytorch-cuda 版本，我们实际上不需要/usr/local/cuda。只需要在安装驱动的前提下，在 python 里面安装 cudatookit 即可。

但是有一种情况例外，就是你要用 C++ CUDA 编写核函数给 pytorch 当做插件。这种情况下就需要/usr/local/cuda 以及 nvcc，cudatookit，而且后面两个版本很多时候需要保持严格一致。

### Cudnn

Cudnn 是一些链接文件，你可以理解成是为了给 cuda 计算加速的东西。同样的我们也可以用以下命令查看/usr/local/cuda 的 cudnn：

![](https://cdn.xyxsw.site/boxcnPD5DbA3NPimtV0kVoDJGmh.png)

以及 pytorch 的 cuda 环境的 cudnn

![](https://cdn.xyxsw.site/boxcnZQ2Mc52Us6ku543l7WPEZd.png)
