# VIT

## 前言

   VIT前Transformer模型被大量应用在NLP自然语言处理当中，而在CV领域，Transformer的注意力机制attention也被广泛应用，比如Se模块，CBAM模块等等注意力模块，这些注意力模块能够帮助提升网络性能。
   
   而**VIT的工作展示了不需要依赖CNN的结构，也可以在图像分类任务上达到很好的效果**。
   
   同时VIT也影响了近2年的CV领域，改变了自2012年AlexNet提出以来卷积神经网络在CV领域的绝对统治地位。


在本节内容中我们会带你了解这一框架。

## 论文

[知乎](https://zhuanlan.zhihu.com/p/356155277)
[论文](https://arxiv.org/abs/2010.11929)

## 模型详解

![](https://cdn.xyxsw.site/boxcn1wqKtwBc6MCJDm7ehvhXac.png)

### 模型主题结构

结构上，VIT 采取的是原始 Transformer 模型，方便开箱即用，即在 encoder-decoder 结构上与 NLP 的 Transform 模型并无差别。

主要做出的贡献在于**数据处理和分类头**

### Patch embedding

#### 从 Word embedding 到 Patch embedding

##### Word embedding

简单来说就是用特殊的向量来表示一个句子中的某个词

即例如

> 今天天气不错，我要去看电影

其中**我**则编码为[0.5，0.6，0.6]

而具体来说 Word embedding 分为以下两步

1. 对 context 进行分词操作。
2. 对分好的词进行 one-hot 编码，根据学习相应的权重对 one-hot 编码进行 N（embedded_dim）维空间的映射.

##### Patch embedding

简单来说 用一个特殊的向量来表示一张图片中某块图

例如

![](https://cdn.xyxsw.site/boxcn1szLG4Y4s0UkY3kkW18Xoc.png)

![](https://cdn.xyxsw.site/boxcnv2inISAGi2xOauc3pxKpCb.png)

其中该张图片的编码为[0.5，0.6，0.3，....]

具体来说

1. 先对图片作分块
   1. 假设原始输入的图片数据是 H * W * C,
   2. 假设每个块的长宽为(P, P)，那么分块的数目为 N=H ∗ W / (P ∗ P)
   3. 其中 vit 的分块是定下每一块的大小然后块的数量为计算结果
2. 然后对每个图片块展平成一维向量
   1. 每个向量大小为 P * P * C
3. 接着对每个向量都做一个线性变换（即全连接层），得到 patch embedding


## 视频

<Bilibili bvid='BV15P4y137jb'/>
