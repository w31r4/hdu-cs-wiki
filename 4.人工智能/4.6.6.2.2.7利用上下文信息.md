# 利用上下文信息

## 概述

- 在对用户进行推荐时，用户所处的空间与时间会对用户的喜好产生影响。例如，最经典的例子，如果当前季节是冬天，推荐系统不应该给用户推荐短袖。这就是一个很经典的时间上下文。同样能被成为上下文信息的包括但不限于，心情，地点等能描述用户当前状态的信息。利用这些上下文信息，我们能将推荐系统的推荐更加精确。

- 将重点讨论基于时间上下文信息的推荐系统

## 时间上下文

### 时间信息效应

- 时间信息对于用户的的影响可以主要分为以下几项：

  - **用户的兴趣是变化的**
    对于一个用户，其幼年时期和青年时期喜欢的动画片是不一样的；晴天和雨天想要的物品是不一样的；一个人开始工作前和开始工作后的需求也是不同的。
    所以应该关注用户的近期行为，确定他的兴趣，最后给予用户推荐。
  - **物品具有生命周期**
    流行物品会随着热度持续火爆一段时间，但最终会无人问津；生活必需品无论在什么时候都有稳定的需求量。
  - **季节效应**
    正如概述中列出的冬衣与夏衣的区别，应该在合适的季节给用户推荐合适的物品。

### 系统时间特性分析

- 当系统由之前的静态系统变成随时间变化的时变系统后，需要关注特性也会发生变化，则需要重新观测一些数据，以推断系统的关于时间变化的特性。
  下面是一些可以用来观测的数据：

  - **确定系统的用户增长数**，以判断系统的增长情况或是衰退情况。
  - **物品的平均在线天数**，即将满足用户物品互动次数的物品标记为在线，测算物品的平均在线天数以标量物品的生命周期。
  - 系统的时效性，判断**相隔一段时间的物品流行度向量的相似度**，若是相隔一段时间的相似度仍然较大，说明经过一段时间后，该物品还是被大众喜欢，则说明这件物品具有持久流行性。而对于系统来说，若是系统中大量物品的相似度变化都不大，则说明这个系统是一个推荐热度较持久物品的系统，说明系统的时效性较弱。
  - 系统对于用户的黏着性，统计**用户的平均活跃天数**，或者计算**相隔一段时间的用户活跃度**，以此判断系统对于用户的留存力或者说黏着性。

### 推荐系统的实时性

- 当引入了时间上下文信息后，推荐系统就可以进行实时性推荐，就类似于观看完一个视频后，立马弹出一系列的相关推荐列表“猜你想看”，存在这样特性的推荐系统有如下的特征：

  - 实时推荐系统能根据用户的行为，实时计算推荐列表，而不是像之前所说的离线计算推荐列表。
  - 推荐系统需要平衡用户短期行为和长期行为，用户的推荐列表需要体现其短期的兴趣变化，但是推荐列表的又不能完全受用户近期行为影响，需要保证推荐列表预测的延续性。

### 推荐算法的时间多样性

- 想象这样一种情况，现在有 ABC 三个系统，A 系统为您推荐您最感兴趣的十样物品，但是不会更新。B 系统为您推荐一百样物品中的十样物品，推荐间隔一周，一周之后的榜单有七件不会是这周的物品。C 系统随机为您推荐一百样物品中的十样物品。

  用推荐系统的思想分析上述三个系统：A 系统缺乏了随时间变化的推荐多样性，所以用户对于其满意度会随着时间推移而下降；B 系统兼顾了时间变化和推荐精度，会得到用户较高的好评；C 系统则是过于随机导致推荐精度下降。

  综上，时间多样性会提高用户的满意度，所以如何在确保精度的条件下提高系统的时间多样性呢？

  - **需要用户在有新行为时，更新推荐列表**
    传统的离线更新的推荐系统无法满足需求，所以需要使用实时推荐系统。
  - **需要用户在没有新行为的时候，经常变化推荐列表**
    通常采取以下三种方法：

    - 生成推荐列表时加入一定的随机性。
    - 记录用户每天得到的推荐列表，在一段时间后，降低列表中用户未出现过行为的物品的权重。
    - 每次给用户使用不同的推荐算法。
  
      当然，对于推荐系统来说，推荐准度的重要性要大于时间多样性，所以应该在尽量保证准度的基础上强化实践多样性，而这个强化的程度，则需要对推荐系统进行多次实验得到。

### 时间上下文推荐算法

- **最近最热门**
  一种最朴素的思想， 在系统引入了时间信息之后，最简单的非个性化推荐算法就是给用户推荐最近最热门的物品。

  给定时间 T，物品 i 在最近的流行度可定义为：

    $$
    n_i(T)= \sum_{(u,i,t) \in Train ,t<T} \frac{1}{1+\alpha(T-t)}
    $$

- **时间上下文相关的 itemCF 算法**
  itemCF 算法所依赖的核心部分，在引入时间信息后可以进行进一步更新

  - **物品相似度** 利用用户行为，计算物品间的相似度，用户在相隔很短的时间内喜欢的物品通常具有更高的相似度，所以可以在相似度计算公式中引入时间信息，使得相似度计算更加准确。
    原本的相似度公式为：

    $$
    sim(i,j)=\frac{\sum_{u\in N(i) \cap N(i)}{1}}{\sqrt{\vert N(i)\vert \vert N(j) \vert}}
    $$  


    引入时间信息后，可更新为： 

    $$
    sim(i,j)=\frac{\sum_{u\in N(i) \cap N(i)}{f(\vert t_{ui} - t_{uj}\vert)}}{\sqrt{\vert N(i)\vert \vert N(j) \vert}}$$  


    其中$f(\vert t_{ui}-t_{uj} \vert)$ 为时间衰减项，其中$t_{ui}$为用户u对物品i产生行为的时间，$f()$ 函数的作用是，用户对i与j的作用时间相距越远，对应函数值越小，相当于对输入因子$\vert t_{ui}-t_{uj} \vert$ 进行一个反比操作。可以找到在数学中许多的衰减函数，例如:

    $$f(\vert t_{ui}-t_{uj} \vert)=\frac{1}{1+\alpha(\vert t_{ui}-t_{uj}\vert)}$$  


    其中$\alpha$ 是时间衰减参数，它的取值与系统的对于自身定义有关系。收到用户兴趣变化的额外影响。

  - **在线推荐** 用户近期行为相比用户很久之前的行为，更能体现用户目前的兴趣，所以在进行预测时，应当加重用户近期行为的权重，但不应该偏离用户长期行为的行为基调。
    原本的用户u对于物品i的兴趣$p(u,i)$ 可通过如下公式计算： 

    $$p(u,i)=\sum_{j\in N(u)}{sim(i,j)}$$  


    引入时间信息可更新为：

    $$
    p(u,i)=\sum_{j\in N(u)\cap S(i,k)}{sim(i,j)\frac{1}{1+\beta \vert t_0-t_{uj}\vert}}
    $$  


    在上面的更新后公式中，$t_0$ 表示当前时间，该公式表明，当 $t_{uj}$ 与 $t_0$ 越靠近，和物品j相似的物品就会在用户u的推荐列表中获得更高的排名。其中的$\beta$和上文的 $\alpha$ 是一样的，需要根据系统的情况选择合适的值。

- **时间上下文相关的userCF算法**
  
    与itemCF算法类似，userCF在引入时间信息后也可以进行更新

  - **用户兴趣相似度** 用户相似度在引入时间信息后，会将用户相同的逆时序选择相似度降低。简单来说，就是A一月BF1长时间在线，二月BF5长时间在线，而B一月BF5长时间在线，二月BF1长时间在线；C行为信息与A相同。如果不引入时间信息，那么AB的相似度与AC的相似度是一样的，而实际上，AC的相似度会大于AB的相似度。

    userCF的用户uv间相似度的基本公式为：  

    $$
    w_{uv}=\frac{\vert N(u)\cap N(v)\vert}{\sqrt{\vert N(u)\cap N(v)\vert}}
    $$  


    其中，$N(u)$ 是用户u喜欢的物品的合集，$N(v)$ 是用户v喜欢的物品的合集。

    引入时间信息后，公式可更新为：

    $$
    w_{uv}=\frac{\sum_{i \in N(u)\cap N(i)}{\frac{1}{1+\alpha \vert t_{ui}-t_{vi}\vert}}}{\sqrt{\vert N(u)\cap N(v)\vert}}
    $$  


    同样增加了一个时间衰减因子，用户uv对于i的作用时间差距越大，那么两人的相似度会相应降低。

  - **相似兴趣用户的最近行为** 对于用户u来说，存在最近行为与用户u相似的用户v，那么用户v的最近行为，将会比用户u很久之前的行为更具有参考价值。

    userCF中用户u对于物品i兴趣的基础公式为：  

    $$
    p(u,i)=\sum_{v\in S(u,k)}{w_{ui}r_{vi}}
    $$  


    其中，$S(u,k)$ 包含了与用户 u 相似度最高的 k 名用户。而对应的$r_{ui}$ ，若用户产生过对i的行为，则其值为1 ，否则为0 。
    引入时间信息更新公式：

    $$
    p(u,i)=\sum_{v\in S(u,k)}{w_{ui}r_{vi}} \frac{1}{1+\alpha(\vert t_0-t_{vi}\vert)}
    $$

- **时间段图模型**
  同样是一个基于图的推荐系统模型，引入时间信息，建立一个二分图时间段图模型：

    $$
    (U,S_U,I,S_I,,E,w,\sigma)
    $$ 


    其中，$U$ 是用户节点集合，$S_U$ 表示用户时间段节点集合，一个用户时间段节点$v_{ut}\in S_U$ 会和用户 $u$ 在时刻 $t$ 喜欢的的物品通过边相连。$I$ 是物品集合，$S_I$ 是物品时间段节点集合，一个物品时间段节点 $v_{it}\in S_I$ 会和所有在时间$t$ 喜欢物品 $i$ 的用户节点相连。  


    $E$ 是边集合，包含两大类边

    第一种：若用户 $u$ 对于物品 $i$ 有行为，则会存在边 $e(u,i)\in E$ ；第二种，若用户 $u$ 对于物品 $i$ 在时间 $t$ 有行为，那么将存在对应的两条边，$e(v_{ut},v_i),e(v_u,v_{it})\in E$ 。 


    而 $w(e)$ 定义了边的权重，$\sigma(e)$ 定义了顶点的权重。具体示例：



    在构建了引入时间信息的图结构后，最简单的思想就是利用PersonalRank算法给用进行个性化推荐。但由于其复杂度较高，所以引入路径融合算法。
    一般来说，图上两个点的相关度强有以下的特征：

    - **两个顶点间有很多路径**

    - **两个顶点间路径比较短**

    - **两点间不经过出度大的点** ，即不经过与很多其他点相连的节点，在推荐系统思维中等效于不与过热门物品关系紧密。

#### 路径融合算法

  - 首先提取两个节点之间，长度小于一个给定值的所有路径。然后根据每条路径经过的不同节点，给予路径不同的权重。最后将所有路径的权重之和，作为两点的相关度。
  设 $P=\lbrace v_1,v_2,...,v_n\rbrace$ 是链接顶点 $v_1$ 到 $v_n$ 的一条路径，这条路径的权重 $\Gamma(P)$ 取决于这条路径所经过的所有顶点和边。

  $$
  \Gamma(P)=\sigma(v_n)\prod_{i=1}^{n-1}{\frac{\sigma(v_i)\cdot w(v_i,v_{i+1})}{\vert out(v_i)\vert ^{\rho}}}
  $$  


  其中，$out(v)$ 是顶点 $v$ 指向的顶点的集合，$\vert out(v) \vert$ 是顶点 $v$ 的出度，$\sigma(v_i)\in(0,1]$ 定义了顶点的权重，$w(v_i,v_{i+1})\in (0,1]$ 定义了边 $e(v_i,v_{i+1})$ 的权重。

  定义了一条边的权重之后，就可以定义顶点之间的相关度。

  对于顶点$v_1,v_n$ ，令$p(v_1,v_n,K)$ 为这两个顶点间距离小于K的所有路径，那么这两个顶点的相关度就可以表示为：

  $$d(v_1,v_n)=\sum_{P\in P(v_1,v_n,K)}{\Gamma(P)}$$  

  而关于路径融合算法的算法实现，可以使用基于图上的广度优先搜索算法实现。

## 地点上下文

### 地点信息效应

- **基于用户当前位置的推荐**：对于用户当前位置，为其推荐距离更近的餐馆，娱乐场所或消费场所。

- **基于用户活跃位置的推荐**：对于用户长期活跃的区域，降低该区域内物品的权重，提高范围外物品的权重，以提高系统的新鲜度。

### 基于位置的推荐算法

- 明尼苏达大学的LARS推荐系统（Location Aware Recommender System,位置感知推荐系统）。

    - **对于数据的预处理**


      将物品分为两类：(1)有空间属性的物品，餐馆，商店，旅游景点。(2)没有空间属性的物品，图书电影等。

      将用户分为两类：(1)有空间属性的用户，(2)另一类用户没有空间属性。

      基于上述的分类，将数据集整理成三个部分：

      （用户，用户位置，物品，评分）：记录了某一地点的用户，对于一个物品的评分。

      （用户，物品，物品位置，评分）：记录了用户对于某一地点的物品的评分。

      （用户，用户位置，物品，物品位置，评分）：记录了某个位置的用户，对于某个地点的物品的评分。


      - **研究前两组数据**：发现两种特征：(1)兴趣本地化，不同位置的用户存在较大的兴趣差异，不同国家和不同地区的差异。(2)活动本地化，一个用户往往在附近的地区活动。

    - **对于不同数据的处理**

      - 第一种数据：LARS的基本思想是，采用树状结构来进行数据集划分。

        (1)例如：将所有用户作为根节点，将国家作为第一级子节点，省作为第二级，依次往下。

        (2)对于某一个具有位置信息的用户，我们就可以将他分配到一个子节点下，而该子节点包含了与当前用户具有相同位置信息的全体用户的行为数据。

        (3)LARS通过该节点的行为数据，利用基本推荐算法进行为用户进行推荐。

        但是，对于上述过程，若是树的深度较大，则划分到每个节点的用户数据将较少，难以训练出一个令人满意的模型。所以有改进方法如下：
        从根节点出发，利用每个中间节点的数据训练出一个模型，而最终的推荐结果，是这一些列推荐模型所产出的推荐结果的加权结果。这个模型也被称为“**金字塔模型**”，其中**深度**是影响这个模型性能的重要参数，选取合适的深度对于该算法十分重要。

      - 第二种数据：对于物品i在用户u推荐列表中的权重公式进行修正
        (1)首先忽略物品的位置信息，利用itemCF算法计算用户u对物品i的兴趣。

        (2)计算物品i对于用户u的代价 $TravelPenalty(u,i)$ ，对于物品i与用户u之前评分的所有物品的位置距离计算平均值，度量方式通常采用交通网络数据。

        (3) 利用公式 

          $$RecScore(u,i)=P(u,i)-TravelPenalty(u,i)$$  


          计算最终的权重。

      - 第三种数据：LARS的处理方法相当于在第二种数据中引入了用户当前位置的信息。
